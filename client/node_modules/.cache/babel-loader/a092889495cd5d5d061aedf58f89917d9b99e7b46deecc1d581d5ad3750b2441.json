{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\ai-interview-model\\\\client\\\\src\\\\InterviewPage.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useCallback, useRef } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst InterviewPage = ({\n  onComplete\n}) => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\n  const [interviewHistory, setInterviewHistory] = useState([]);\n  const [questionCount, setQuestionCount] = useState(0);\n  const recognitionRef = useRef(null);\n  const synthRef = useRef(null);\n  const sendToAI = useCallback(async text => {\n    const updatedHistory = [...interviewHistory, {\n      role: 'user',\n      text\n    }];\n    setInterviewHistory(updatedHistory);\n    try {\n      const response = await fetch('http://localhost:3001/api/chat', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          chatHistory: updatedHistory,\n          userText: text\n        })\n      });\n      const data = await response.json();\n      // Set the new AI text to trigger the next interview step\n      setAiText(data.message);\n      setQuestionCount(prevCount => prevCount + 1);\n    } catch (error) {\n      console.error('Error fetching AI response:', error);\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\n    }\n  }, [interviewHistory]);\n  const speakAndListen = useCallback(text => {\n    // Add AI's response to history\n    setInterviewHistory(prevHistory => [...prevHistory, {\n      role: 'ai',\n      text: text\n    }]);\n    const utterance = new SpeechSynthesisUtterance(text);\n\n    // This is the CRUCIAL part: Only start listening AFTER the AI has finished speaking\n    utterance.onend = () => {\n      console.log('AI finished speaking. Now listening...');\n      if (questionCount < 5) {\n        if (recognitionRef.current) {\n          setIsListening(true);\n          recognitionRef.current.start();\n        }\n      } else {\n        onComplete([...interviewHistory, {\n          role: 'ai',\n          text: aiText\n        }]);\n      }\n    };\n    if (synthRef.current) {\n      synthRef.current.speak(utterance);\n    }\n  }, [onComplete, interviewHistory, questionCount, aiText]);\n\n  // --- Step 1: Initialize Objects and Clean Up (Runs Once) ---\n  useEffect(() => {\n    recognitionRef.current = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n    recognitionRef.current.continuous = false;\n    recognitionRef.current.interimResults = false;\n    recognitionRef.current.lang = 'en-US';\n    synthRef.current = window.speechSynthesis;\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n    };\n  }, []);\n\n  // --- Step 2: Set Up Event Listeners (Runs when `sendToAI` changes) ---\n  useEffect(() => {\n    if (!recognitionRef.current) return;\n    recognitionRef.current.onresult = event => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      setTranscript(text);\n      setIsListening(false);\n      sendToAI(text);\n    };\n    recognitionRef.current.onend = () => {\n      setIsListening(false);\n      // The `speakAndListen` function will handle starting the next turn,\n      // so we don't need to do anything here.\n    };\n    recognitionRef.current.onerror = event => {\n      console.error('Speech recognition error:', event.error);\n      setIsListening(false);\n      // If there's an error, we should stop the process\n      // to avoid infinite loops and give the user a chance to restart manually.\n      recognitionRef.current.stop();\n    };\n  }, [sendToAI]);\n\n  // --- Step 3: Manage the Interview Flow ---\n  // This useEffect triggers the next action whenever the `aiText` state changes.\n  useEffect(() => {\n    if (aiText) {\n      speakAndListen(aiText);\n    }\n  }, [aiText, speakAndListen]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"AI: \", aiText]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 110,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"You: \", transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 111,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: () => {\n          if (!isListening && recognitionRef.current) {\n            // Manually start listening if the user clicks the button\n            setIsListening(true);\n            recognitionRef.current.start();\n          }\n        },\n        disabled: isListening,\n        children: isListening ? \"Listening...\" : \"Speak now\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 113,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 112,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 109,\n    columnNumber: 5\n  }, this);\n};\n_s(InterviewPage, \"EhOP+bXC+5YJ5cHKGm+9Iz5T/N8=\");\n_c = InterviewPage;\nexport default InterviewPage;\nvar _c;\n$RefreshReg$(_c, \"InterviewPage\");","map":{"version":3,"names":["React","useState","useEffect","useCallback","useRef","jsxDEV","_jsxDEV","InterviewPage","onComplete","_s","transcript","setTranscript","isListening","setIsListening","aiText","setAiText","interviewHistory","setInterviewHistory","questionCount","setQuestionCount","recognitionRef","synthRef","sendToAI","text","updatedHistory","role","response","fetch","method","headers","body","JSON","stringify","chatHistory","userText","data","json","message","prevCount","error","console","speakAndListen","prevHistory","utterance","SpeechSynthesisUtterance","onend","log","current","start","speak","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","speechSynthesis","stop","onresult","event","last","results","length","onerror","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","_c","$RefreshReg$"],"sources":["C:/Users/Lenovo/Desktop/ai-interview-model/client/src/InterviewPage.js"],"sourcesContent":["import React, { useState, useEffect, useCallback, useRef } from 'react';\r\n\r\nconst InterviewPage = ({ onComplete }) => {\r\n  const [transcript, setTranscript] = useState('');\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\r\n  const [interviewHistory, setInterviewHistory] = useState([]);\r\n  const [questionCount, setQuestionCount] = useState(0);\r\n\r\n  const recognitionRef = useRef(null);\r\n  const synthRef = useRef(null);\r\n\r\n  const sendToAI = useCallback(async (text) => {\r\n    const updatedHistory = [...interviewHistory, { role: 'user', text }];\r\n    setInterviewHistory(updatedHistory);\r\n    \r\n    try {\r\n      const response = await fetch('http://localhost:3001/api/chat', {\r\n        method: 'POST',\r\n        headers: { 'Content-Type': 'application/json' },\r\n        body: JSON.stringify({ chatHistory: updatedHistory, userText: text }),\r\n      });\r\n      const data = await response.json();\r\n      // Set the new AI text to trigger the next interview step\r\n      setAiText(data.message);\r\n      setQuestionCount(prevCount => prevCount + 1);\r\n    } catch (error) {\r\n      console.error('Error fetching AI response:', error);\r\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\r\n    }\r\n  }, [interviewHistory]);\r\n\r\n  const speakAndListen = useCallback((text) => {\r\n    // Add AI's response to history\r\n    setInterviewHistory(prevHistory => [...prevHistory, { role: 'ai', text: text }]);\r\n\r\n    const utterance = new SpeechSynthesisUtterance(text);\r\n    \r\n    // This is the CRUCIAL part: Only start listening AFTER the AI has finished speaking\r\n    utterance.onend = () => {\r\n      console.log('AI finished speaking. Now listening...');\r\n      if (questionCount < 5) {\r\n        if (recognitionRef.current) {\r\n          setIsListening(true);\r\n          recognitionRef.current.start();\r\n        }\r\n      } else {\r\n        onComplete([...interviewHistory, { role: 'ai', text: aiText }]);\r\n      }\r\n    };\r\n    \r\n    if (synthRef.current) {\r\n      synthRef.current.speak(utterance);\r\n    }\r\n  }, [onComplete, interviewHistory, questionCount, aiText]);\r\n\r\n  // --- Step 1: Initialize Objects and Clean Up (Runs Once) ---\r\n  useEffect(() => {\r\n    recognitionRef.current = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\r\n    recognitionRef.current.continuous = false;\r\n    recognitionRef.current.interimResults = false;\r\n    recognitionRef.current.lang = 'en-US';\r\n\r\n    synthRef.current = window.speechSynthesis;\r\n\r\n    return () => {\r\n      if (recognitionRef.current) {\r\n        recognitionRef.current.stop();\r\n      }\r\n    };\r\n  }, []);\r\n\r\n  // --- Step 2: Set Up Event Listeners (Runs when `sendToAI` changes) ---\r\n  useEffect(() => {\r\n    if (!recognitionRef.current) return;\r\n\r\n    recognitionRef.current.onresult = (event) => {\r\n      const last = event.results.length - 1;\r\n      const text = event.results[last][0].transcript;\r\n      setTranscript(text);\r\n      setIsListening(false);\r\n      sendToAI(text);\r\n    };\r\n\r\n    recognitionRef.current.onend = () => {\r\n      setIsListening(false);\r\n      // The `speakAndListen` function will handle starting the next turn,\r\n      // so we don't need to do anything here.\r\n    };\r\n\r\n    recognitionRef.current.onerror = (event) => {\r\n      console.error('Speech recognition error:', event.error);\r\n      setIsListening(false);\r\n      // If there's an error, we should stop the process\r\n      // to avoid infinite loops and give the user a chance to restart manually.\r\n      recognitionRef.current.stop();\r\n    };\r\n  }, [sendToAI]);\r\n\r\n  // --- Step 3: Manage the Interview Flow ---\r\n  // This useEffect triggers the next action whenever the `aiText` state changes.\r\n  useEffect(() => {\r\n    if (aiText) {\r\n      speakAndListen(aiText);\r\n    }\r\n  }, [aiText, speakAndListen]);\r\n\r\n  return (\r\n    <div>\r\n      <p>AI: {aiText}</p>\r\n      <p>You: {transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")}</p>\r\n      <div>\r\n        <button onClick={() => {\r\n            if (!isListening && recognitionRef.current) {\r\n                // Manually start listening if the user clicks the button\r\n                setIsListening(true);\r\n                recognitionRef.current.start();\r\n            }\r\n        }} disabled={isListening}>\r\n          {isListening ? \"Listening...\" : \"Speak now\"}\r\n        </button>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default InterviewPage;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,WAAW,EAAEC,MAAM,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExE,MAAMC,aAAa,GAAGA,CAAC;EAAEC;AAAW,CAAC,KAAK;EAAAC,EAAA;EACxC,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACW,WAAW,EAAEC,cAAc,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACa,MAAM,EAAEC,SAAS,CAAC,GAAGd,QAAQ,CAAC,kFAAkF,CAAC;EACxH,MAAM,CAACe,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGhB,QAAQ,CAAC,EAAE,CAAC;EAC5D,MAAM,CAACiB,aAAa,EAAEC,gBAAgB,CAAC,GAAGlB,QAAQ,CAAC,CAAC,CAAC;EAErD,MAAMmB,cAAc,GAAGhB,MAAM,CAAC,IAAI,CAAC;EACnC,MAAMiB,QAAQ,GAAGjB,MAAM,CAAC,IAAI,CAAC;EAE7B,MAAMkB,QAAQ,GAAGnB,WAAW,CAAC,MAAOoB,IAAI,IAAK;IAC3C,MAAMC,cAAc,GAAG,CAAC,GAAGR,gBAAgB,EAAE;MAAES,IAAI,EAAE,MAAM;MAAEF;IAAK,CAAC,CAAC;IACpEN,mBAAmB,CAACO,cAAc,CAAC;IAEnC,IAAI;MACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,gCAAgC,EAAE;QAC7DC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEC,WAAW,EAAET,cAAc;UAAEU,QAAQ,EAAEX;QAAK,CAAC;MACtE,CAAC,CAAC;MACF,MAAMY,IAAI,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;MAClC;MACArB,SAAS,CAACoB,IAAI,CAACE,OAAO,CAAC;MACvBlB,gBAAgB,CAACmB,SAAS,IAAIA,SAAS,GAAG,CAAC,CAAC;IAC9C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACnDxB,SAAS,CAAC,6DAA6D,CAAC;IAC1E;EACF,CAAC,EAAE,CAACC,gBAAgB,CAAC,CAAC;EAEtB,MAAMyB,cAAc,GAAGtC,WAAW,CAAEoB,IAAI,IAAK;IAC3C;IACAN,mBAAmB,CAACyB,WAAW,IAAI,CAAC,GAAGA,WAAW,EAAE;MAAEjB,IAAI,EAAE,IAAI;MAAEF,IAAI,EAAEA;IAAK,CAAC,CAAC,CAAC;IAEhF,MAAMoB,SAAS,GAAG,IAAIC,wBAAwB,CAACrB,IAAI,CAAC;;IAEpD;IACAoB,SAAS,CAACE,KAAK,GAAG,MAAM;MACtBL,OAAO,CAACM,GAAG,CAAC,wCAAwC,CAAC;MACrD,IAAI5B,aAAa,GAAG,CAAC,EAAE;QACrB,IAAIE,cAAc,CAAC2B,OAAO,EAAE;UAC1BlC,cAAc,CAAC,IAAI,CAAC;UACpBO,cAAc,CAAC2B,OAAO,CAACC,KAAK,CAAC,CAAC;QAChC;MACF,CAAC,MAAM;QACLxC,UAAU,CAAC,CAAC,GAAGQ,gBAAgB,EAAE;UAAES,IAAI,EAAE,IAAI;UAAEF,IAAI,EAAET;QAAO,CAAC,CAAC,CAAC;MACjE;IACF,CAAC;IAED,IAAIO,QAAQ,CAAC0B,OAAO,EAAE;MACpB1B,QAAQ,CAAC0B,OAAO,CAACE,KAAK,CAACN,SAAS,CAAC;IACnC;EACF,CAAC,EAAE,CAACnC,UAAU,EAAEQ,gBAAgB,EAAEE,aAAa,EAAEJ,MAAM,CAAC,CAAC;;EAEzD;EACAZ,SAAS,CAAC,MAAM;IACdkB,cAAc,CAAC2B,OAAO,GAAG,KAAKG,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE,CAAC;IAC3FhC,cAAc,CAAC2B,OAAO,CAACM,UAAU,GAAG,KAAK;IACzCjC,cAAc,CAAC2B,OAAO,CAACO,cAAc,GAAG,KAAK;IAC7ClC,cAAc,CAAC2B,OAAO,CAACQ,IAAI,GAAG,OAAO;IAErClC,QAAQ,CAAC0B,OAAO,GAAGG,MAAM,CAACM,eAAe;IAEzC,OAAO,MAAM;MACX,IAAIpC,cAAc,CAAC2B,OAAO,EAAE;QAC1B3B,cAAc,CAAC2B,OAAO,CAACU,IAAI,CAAC,CAAC;MAC/B;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;;EAEN;EACAvD,SAAS,CAAC,MAAM;IACd,IAAI,CAACkB,cAAc,CAAC2B,OAAO,EAAE;IAE7B3B,cAAc,CAAC2B,OAAO,CAACW,QAAQ,GAAIC,KAAK,IAAK;MAC3C,MAAMC,IAAI,GAAGD,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACrC,MAAMvC,IAAI,GAAGoC,KAAK,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAAClD,UAAU;MAC9CC,aAAa,CAACY,IAAI,CAAC;MACnBV,cAAc,CAAC,KAAK,CAAC;MACrBS,QAAQ,CAACC,IAAI,CAAC;IAChB,CAAC;IAEDH,cAAc,CAAC2B,OAAO,CAACF,KAAK,GAAG,MAAM;MACnChC,cAAc,CAAC,KAAK,CAAC;MACrB;MACA;IACF,CAAC;IAEDO,cAAc,CAAC2B,OAAO,CAACgB,OAAO,GAAIJ,KAAK,IAAK;MAC1CnB,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEoB,KAAK,CAACpB,KAAK,CAAC;MACvD1B,cAAc,CAAC,KAAK,CAAC;MACrB;MACA;MACAO,cAAc,CAAC2B,OAAO,CAACU,IAAI,CAAC,CAAC;IAC/B,CAAC;EACH,CAAC,EAAE,CAACnC,QAAQ,CAAC,CAAC;;EAEd;EACA;EACApB,SAAS,CAAC,MAAM;IACd,IAAIY,MAAM,EAAE;MACV2B,cAAc,CAAC3B,MAAM,CAAC;IACxB;EACF,CAAC,EAAE,CAACA,MAAM,EAAE2B,cAAc,CAAC,CAAC;EAE5B,oBACEnC,OAAA;IAAA0D,QAAA,gBACE1D,OAAA;MAAA0D,QAAA,GAAG,MAAI,EAAClD,MAAM;IAAA;MAAAmD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACnB9D,OAAA;MAAA0D,QAAA,GAAG,OAAK,EAACtD,UAAU,KAAKE,WAAW,GAAG,cAAc,GAAG,8BAA8B,CAAC;IAAA;MAAAqD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAC3F9D,OAAA;MAAA0D,QAAA,eACE1D,OAAA;QAAQ+D,OAAO,EAAEA,CAAA,KAAM;UACnB,IAAI,CAACzD,WAAW,IAAIQ,cAAc,CAAC2B,OAAO,EAAE;YACxC;YACAlC,cAAc,CAAC,IAAI,CAAC;YACpBO,cAAc,CAAC2B,OAAO,CAACC,KAAK,CAAC,CAAC;UAClC;QACJ,CAAE;QAACsB,QAAQ,EAAE1D,WAAY;QAAAoD,QAAA,EACtBpD,WAAW,GAAG,cAAc,GAAG;MAAW;QAAAqD,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACrC;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAC3D,EAAA,CA1HIF,aAAa;AAAAgE,EAAA,GAAbhE,aAAa;AA4HnB,eAAeA,aAAa;AAAC,IAAAgE,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}