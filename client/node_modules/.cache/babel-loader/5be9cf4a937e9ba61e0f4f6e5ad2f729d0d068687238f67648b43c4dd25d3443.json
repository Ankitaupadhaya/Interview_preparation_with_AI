{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\ai-interview-model\\\\client\\\\src\\\\InterviewPage.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useCallback, useRef } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst InterviewPage = ({\n  onComplete\n}) => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\n  const [interviewHistory, setInterviewHistory] = useState([]);\n  const [questionCount, setQuestionCount] = useState(0);\n\n  // Use useRef to create SpeechRecognition and SpeechSynthesis objects once\n  const recognitionRef = useRef(null);\n  const synthRef = useRef(null);\n\n  // --- Step 1: Initialize Objects and Set Up Listeners ONCE ---\n  // This useEffect runs only on the first render to set everything up.\n  useEffect(() => {\n    // Initialize Web Speech API for speech-to-text\n    recognitionRef.current = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n    recognitionRef.current.continuous = false;\n    recognitionRef.current.interimResults = false;\n    recognitionRef.current.lang = 'en-US';\n\n    // Initialize Web Speech API for text-to-speech\n    synthRef.current = window.speechSynthesis;\n\n    // Set up all event handlers for the recognition object\n    recognitionRef.current.onresult = event => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      setTranscript(text);\n      setIsListening(false);\n      sendToAI(text); // Process user response with the AI\n    };\n    recognitionRef.current.onend = () => {\n      setIsListening(false);\n      // The recognition has ended, so we are ready for the next step.\n      // This is the correct place to handle the next action if needed,\n      // but in our current sequential flow, the `speakAndListen` takes over.\n    };\n    recognitionRef.current.onerror = event => {\n      console.error('Speech recognition error:', event.error);\n      setIsListening(false);\n      // It's safer to stop the entire process on a persistent error\n      // than to try and restart, which could cause an infinite loop.\n      // We will rely on the user to click the button again if needed.\n    };\n\n    // Cleanup function to stop recognition when the component unmounts\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n    };\n  }, [sendToAI]); // sendToAI is a dependency to ensure onresult has the latest version\n\n  // --- Step 2: The Core Interview Logic (Speak then Listen) ---\n  const speakAndListen = useCallback(text => {\n    // Add the AI's response to history\n    setInterviewHistory(prevHistory => [...prevHistory, {\n      role: 'ai',\n      text: text\n    }]);\n    const utterance = new SpeechSynthesisUtterance(text);\n    utterance.onend = () => {\n      // After AI finishes speaking, check if the interview is over\n      if (questionCount < 5) {\n        if (recognitionRef.current) {\n          setIsListening(true);\n          // This is the ONLY place where `recognition.start()` is called\n          recognitionRef.current.start();\n        }\n      } else {\n        // Interview completed\n        onComplete([...interviewHistory, {\n          role: 'ai',\n          text: aiText\n        }]);\n      }\n    };\n    if (synthRef.current) {\n      synthRef.current.speak(utterance);\n    }\n  }, [onComplete, interviewHistory, questionCount, aiText]);\n\n  // --- Step 3: Trigger the Next Step of the Interview ---\n  // This useEffect will run when `aiText` changes, which signals it's time for the AI's turn.\n  useEffect(() => {\n    if (aiText) {\n      speakAndListen(aiText);\n    }\n  }, [aiText, speakAndListen]);\n\n  // --- Step 4: The UI ---\n  // The UI should now be controlled by the `isListening` state.\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"AI: \", aiText]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 95,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"You: \", transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 96,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: () => {\n          // This button now serves as a manual \"restart\" button in case of an error or initial start.\n          if (!isListening && recognitionRef.current) {\n            recognitionRef.current.start();\n            setIsListening(true);\n          }\n        },\n        disabled: isListening,\n        children: isListening ? \"Listening...\" : \"Speak now\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 100,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 98,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 94,\n    columnNumber: 5\n  }, this);\n};\n_s(InterviewPage, \"GWK0jbchImACHB7hg5LpLolAy1U=\");\n_c = InterviewPage;\nexport default InterviewPage;\nvar _c;\n$RefreshReg$(_c, \"InterviewPage\");","map":{"version":3,"names":["React","useState","useEffect","useCallback","useRef","jsxDEV","_jsxDEV","InterviewPage","onComplete","_s","transcript","setTranscript","isListening","setIsListening","aiText","setAiText","interviewHistory","setInterviewHistory","questionCount","setQuestionCount","recognitionRef","synthRef","current","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","speechSynthesis","onresult","event","last","results","length","text","sendToAI","onend","onerror","console","error","stop","speakAndListen","prevHistory","role","utterance","SpeechSynthesisUtterance","start","speak","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","_c","$RefreshReg$"],"sources":["C:/Users/Lenovo/Desktop/ai-interview-model/client/src/InterviewPage.js"],"sourcesContent":["import React, { useState, useEffect, useCallback, useRef } from 'react';\r\n\r\nconst InterviewPage = ({ onComplete }) => {\r\n  const [transcript, setTranscript] = useState('');\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\r\n  const [interviewHistory, setInterviewHistory] = useState([]);\r\n  const [questionCount, setQuestionCount] = useState(0);\r\n\r\n  // Use useRef to create SpeechRecognition and SpeechSynthesis objects once\r\n  const recognitionRef = useRef(null);\r\n  const synthRef = useRef(null);\r\n\r\n  // --- Step 1: Initialize Objects and Set Up Listeners ONCE ---\r\n  // This useEffect runs only on the first render to set everything up.\r\n  useEffect(() => {\r\n    // Initialize Web Speech API for speech-to-text\r\n    recognitionRef.current = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\r\n    recognitionRef.current.continuous = false;\r\n    recognitionRef.current.interimResults = false;\r\n    recognitionRef.current.lang = 'en-US';\r\n\r\n    // Initialize Web Speech API for text-to-speech\r\n    synthRef.current = window.speechSynthesis;\r\n\r\n    // Set up all event handlers for the recognition object\r\n    recognitionRef.current.onresult = (event) => {\r\n      const last = event.results.length - 1;\r\n      const text = event.results[last][0].transcript;\r\n      setTranscript(text);\r\n      setIsListening(false);\r\n      sendToAI(text); // Process user response with the AI\r\n    };\r\n\r\n    recognitionRef.current.onend = () => {\r\n      setIsListening(false);\r\n      // The recognition has ended, so we are ready for the next step.\r\n      // This is the correct place to handle the next action if needed,\r\n      // but in our current sequential flow, the `speakAndListen` takes over.\r\n    };\r\n\r\n    recognitionRef.current.onerror = (event) => {\r\n      console.error('Speech recognition error:', event.error);\r\n      setIsListening(false);\r\n      // It's safer to stop the entire process on a persistent error\r\n      // than to try and restart, which could cause an infinite loop.\r\n      // We will rely on the user to click the button again if needed.\r\n    };\r\n    \r\n    // Cleanup function to stop recognition when the component unmounts\r\n    return () => {\r\n      if (recognitionRef.current) {\r\n        recognitionRef.current.stop();\r\n      }\r\n    };\r\n  }, [sendToAI]); // sendToAI is a dependency to ensure onresult has the latest version\r\n\r\n  // --- Step 2: The Core Interview Logic (Speak then Listen) ---\r\n  const speakAndListen = useCallback((text) => {\r\n    // Add the AI's response to history\r\n    setInterviewHistory(prevHistory => [...prevHistory, { role: 'ai', text: text }]);\r\n\r\n    const utterance = new SpeechSynthesisUtterance(text);\r\n    utterance.onend = () => {\r\n      // After AI finishes speaking, check if the interview is over\r\n      if (questionCount < 5) {\r\n        if (recognitionRef.current) {\r\n          setIsListening(true);\r\n          // This is the ONLY place where `recognition.start()` is called\r\n          recognitionRef.current.start();\r\n        }\r\n      } else {\r\n        // Interview completed\r\n        onComplete([...interviewHistory, { role: 'ai', text: aiText }]);\r\n      }\r\n    };\r\n\r\n    if (synthRef.current) {\r\n      synthRef.current.speak(utterance);\r\n    }\r\n  }, [onComplete, interviewHistory, questionCount, aiText]);\r\n\r\n  // --- Step 3: Trigger the Next Step of the Interview ---\r\n  // This useEffect will run when `aiText` changes, which signals it's time for the AI's turn.\r\n  useEffect(() => {\r\n    if (aiText) {\r\n      speakAndListen(aiText);\r\n    }\r\n  }, [aiText, speakAndListen]);\r\n\r\n  // --- Step 4: The UI ---\r\n  // The UI should now be controlled by the `isListening` state.\r\n  return (\r\n    <div>\r\n      <p>AI: {aiText}</p>\r\n      <p>You: {transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")}</p>\r\n      \r\n      <div>\r\n        {/* The button is now disabled to prevent accidental clicks while the assistant is speaking or listening */}\r\n        <button onClick={() => {\r\n            // This button now serves as a manual \"restart\" button in case of an error or initial start.\r\n            if (!isListening && recognitionRef.current) {\r\n                recognitionRef.current.start();\r\n                setIsListening(true);\r\n            }\r\n        }} disabled={isListening}>\r\n          {isListening ? \"Listening...\" : \"Speak now\"}\r\n        </button>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default InterviewPage;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,WAAW,EAAEC,MAAM,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExE,MAAMC,aAAa,GAAGA,CAAC;EAAEC;AAAW,CAAC,KAAK;EAAAC,EAAA;EACxC,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACW,WAAW,EAAEC,cAAc,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACa,MAAM,EAAEC,SAAS,CAAC,GAAGd,QAAQ,CAAC,kFAAkF,CAAC;EACxH,MAAM,CAACe,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGhB,QAAQ,CAAC,EAAE,CAAC;EAC5D,MAAM,CAACiB,aAAa,EAAEC,gBAAgB,CAAC,GAAGlB,QAAQ,CAAC,CAAC,CAAC;;EAErD;EACA,MAAMmB,cAAc,GAAGhB,MAAM,CAAC,IAAI,CAAC;EACnC,MAAMiB,QAAQ,GAAGjB,MAAM,CAAC,IAAI,CAAC;;EAE7B;EACA;EACAF,SAAS,CAAC,MAAM;IACd;IACAkB,cAAc,CAACE,OAAO,GAAG,KAAKC,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE,CAAC;IAC3FL,cAAc,CAACE,OAAO,CAACI,UAAU,GAAG,KAAK;IACzCN,cAAc,CAACE,OAAO,CAACK,cAAc,GAAG,KAAK;IAC7CP,cAAc,CAACE,OAAO,CAACM,IAAI,GAAG,OAAO;;IAErC;IACAP,QAAQ,CAACC,OAAO,GAAGC,MAAM,CAACM,eAAe;;IAEzC;IACAT,cAAc,CAACE,OAAO,CAACQ,QAAQ,GAAIC,KAAK,IAAK;MAC3C,MAAMC,IAAI,GAAGD,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACrC,MAAMC,IAAI,GAAGJ,KAAK,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAACtB,UAAU;MAC9CC,aAAa,CAACwB,IAAI,CAAC;MACnBtB,cAAc,CAAC,KAAK,CAAC;MACrBuB,QAAQ,CAACD,IAAI,CAAC,CAAC,CAAC;IAClB,CAAC;IAEDf,cAAc,CAACE,OAAO,CAACe,KAAK,GAAG,MAAM;MACnCxB,cAAc,CAAC,KAAK,CAAC;MACrB;MACA;MACA;IACF,CAAC;IAEDO,cAAc,CAACE,OAAO,CAACgB,OAAO,GAAIP,KAAK,IAAK;MAC1CQ,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAET,KAAK,CAACS,KAAK,CAAC;MACvD3B,cAAc,CAAC,KAAK,CAAC;MACrB;MACA;MACA;IACF,CAAC;;IAED;IACA,OAAO,MAAM;MACX,IAAIO,cAAc,CAACE,OAAO,EAAE;QAC1BF,cAAc,CAACE,OAAO,CAACmB,IAAI,CAAC,CAAC;MAC/B;IACF,CAAC;EACH,CAAC,EAAE,CAACL,QAAQ,CAAC,CAAC,CAAC,CAAC;;EAEhB;EACA,MAAMM,cAAc,GAAGvC,WAAW,CAAEgC,IAAI,IAAK;IAC3C;IACAlB,mBAAmB,CAAC0B,WAAW,IAAI,CAAC,GAAGA,WAAW,EAAE;MAAEC,IAAI,EAAE,IAAI;MAAET,IAAI,EAAEA;IAAK,CAAC,CAAC,CAAC;IAEhF,MAAMU,SAAS,GAAG,IAAIC,wBAAwB,CAACX,IAAI,CAAC;IACpDU,SAAS,CAACR,KAAK,GAAG,MAAM;MACtB;MACA,IAAInB,aAAa,GAAG,CAAC,EAAE;QACrB,IAAIE,cAAc,CAACE,OAAO,EAAE;UAC1BT,cAAc,CAAC,IAAI,CAAC;UACpB;UACAO,cAAc,CAACE,OAAO,CAACyB,KAAK,CAAC,CAAC;QAChC;MACF,CAAC,MAAM;QACL;QACAvC,UAAU,CAAC,CAAC,GAAGQ,gBAAgB,EAAE;UAAE4B,IAAI,EAAE,IAAI;UAAET,IAAI,EAAErB;QAAO,CAAC,CAAC,CAAC;MACjE;IACF,CAAC;IAED,IAAIO,QAAQ,CAACC,OAAO,EAAE;MACpBD,QAAQ,CAACC,OAAO,CAAC0B,KAAK,CAACH,SAAS,CAAC;IACnC;EACF,CAAC,EAAE,CAACrC,UAAU,EAAEQ,gBAAgB,EAAEE,aAAa,EAAEJ,MAAM,CAAC,CAAC;;EAEzD;EACA;EACAZ,SAAS,CAAC,MAAM;IACd,IAAIY,MAAM,EAAE;MACV4B,cAAc,CAAC5B,MAAM,CAAC;IACxB;EACF,CAAC,EAAE,CAACA,MAAM,EAAE4B,cAAc,CAAC,CAAC;;EAE5B;EACA;EACA,oBACEpC,OAAA;IAAA2C,QAAA,gBACE3C,OAAA;MAAA2C,QAAA,GAAG,MAAI,EAACnC,MAAM;IAAA;MAAAoC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACnB/C,OAAA;MAAA2C,QAAA,GAAG,OAAK,EAACvC,UAAU,KAAKE,WAAW,GAAG,cAAc,GAAG,8BAA8B,CAAC;IAAA;MAAAsC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAE3F/C,OAAA;MAAA2C,QAAA,eAEE3C,OAAA;QAAQgD,OAAO,EAAEA,CAAA,KAAM;UACnB;UACA,IAAI,CAAC1C,WAAW,IAAIQ,cAAc,CAACE,OAAO,EAAE;YACxCF,cAAc,CAACE,OAAO,CAACyB,KAAK,CAAC,CAAC;YAC9BlC,cAAc,CAAC,IAAI,CAAC;UACxB;QACJ,CAAE;QAAC0C,QAAQ,EAAE3C,WAAY;QAAAqC,QAAA,EACtBrC,WAAW,GAAG,cAAc,GAAG;MAAW;QAAAsC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACrC;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAC5C,EAAA,CA7GIF,aAAa;AAAAiD,EAAA,GAAbjD,aAAa;AA+GnB,eAAeA,aAAa;AAAC,IAAAiD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}