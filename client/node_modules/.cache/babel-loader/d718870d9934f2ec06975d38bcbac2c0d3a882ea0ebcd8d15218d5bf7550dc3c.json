{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\ai-interview-model\\\\client\\\\src\\\\InterviewPage.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useCallback } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst InterviewPage = ({\n  onComplete\n}) => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\n  const [interviewHistory, setInterviewHistory] = useState([]);\n  const [questionCount, setQuestionCount] = useState(0);\n\n  // Initialize Web Speech API for speech-to-text\n  // The 'recognition' object must be created once and reused.\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n  recognition.continuous = false;\n  recognition.interimResults = false;\n  recognition.lang = 'en-US';\n\n  // Initialize Web Speech API for text-to-speech\n  const synth = window.speechSynthesis;\n\n  // Function to start voice recognition\n  const startListening = useCallback(() => {\n    setIsListening(true);\n    recognition.start();\n  }, [recognition]);\n\n  // Function to send user transcript to the backend for an AI response\n  const sendToAI = useCallback(async text => {\n    const updatedHistory = [...interviewHistory, {\n      role: 'user',\n      text\n    }];\n    setInterviewHistory(updatedHistory);\n    try {\n      const response = await fetch('http://localhost:3001/api/chat', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          chatHistory: updatedHistory,\n          userText: text\n        })\n      });\n      const data = await response.json();\n      setAiText(data.message);\n      setQuestionCount(prevCount => prevCount + 1);\n    } catch (error) {\n      console.error('Error fetching AI response:', error);\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\n    }\n  }, [interviewHistory]);\n\n  // Main effect to handle the interview flow\n  // This effect runs whenever aiText changes, triggering the next step.\n  useEffect(() => {\n    if (aiText) {\n      // Add the AI's response to the history only after it has been spoken\n      setInterviewHistory(prevHistory => [...prevHistory, {\n        role: 'ai',\n        text: aiText\n      }]);\n      const utterance = new SpeechSynthesisUtterance(aiText);\n      utterance.onend = () => {\n        // After the AI finishes speaking, check if the interview is over\n        if (questionCount < 5) {\n          startListening();\n        } else {\n          // Interview completed, navigate to the result page with the full history.\n          onComplete([...interviewHistory, {\n            role: 'ai',\n            text: aiText\n          }]);\n        }\n      };\n      synth.speak(utterance);\n    }\n  }, [aiText, synth, startListening, onComplete, interviewHistory, questionCount]);\n\n  // Effect to handle speech-to-text results and errors\n  useEffect(() => {\n    recognition.onresult = event => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      setTranscript(text);\n      setIsListening(false);\n      sendToAI(text);\n    };\n    recognition.onerror = event => {\n      console.error('Speech recognition error:', event.error);\n      setIsListening(false);\n      // Automatically start listening again after an error to prevent a total freeze\n      if (questionCount < 5) {\n        startListening();\n      }\n    };\n    return () => {\n      recognition.stop();\n    };\n  }, [sendToAI, recognition, questionCount, startListening]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"AI: \", aiText]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"You: \", transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: startListening,\n        disabled: isListening,\n        children: isListening ? \"Listening...\" : \"Speak now\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 97,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 96,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 92,\n    columnNumber: 5\n  }, this);\n};\n_s(InterviewPage, \"jQ3vtOt/Fg171vAp94t0jZZO26U=\");\n_c = InterviewPage;\nexport default InterviewPage;\nvar _c;\n$RefreshReg$(_c, \"InterviewPage\");","map":{"version":3,"names":["React","useState","useEffect","useCallback","jsxDEV","_jsxDEV","InterviewPage","onComplete","_s","transcript","setTranscript","isListening","setIsListening","aiText","setAiText","interviewHistory","setInterviewHistory","questionCount","setQuestionCount","recognition","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","synth","speechSynthesis","startListening","start","sendToAI","text","updatedHistory","role","response","fetch","method","headers","body","JSON","stringify","chatHistory","userText","data","json","message","prevCount","error","console","prevHistory","utterance","SpeechSynthesisUtterance","onend","speak","onresult","event","last","results","length","onerror","stop","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","_c","$RefreshReg$"],"sources":["C:/Users/Lenovo/Desktop/ai-interview-model/client/src/InterviewPage.js"],"sourcesContent":["import React, { useState, useEffect, useCallback } from 'react';\r\n\r\nconst InterviewPage = ({ onComplete }) => {\r\n  const [transcript, setTranscript] = useState('');\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [aiText, setAiText] = useState(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\r\n  const [interviewHistory, setInterviewHistory] = useState([]);\r\n  const [questionCount, setQuestionCount] = useState(0);\r\n\r\n  // Initialize Web Speech API for speech-to-text\r\n  // The 'recognition' object must be created once and reused.\r\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\r\n  recognition.continuous = false;\r\n  recognition.interimResults = false;\r\n  recognition.lang = 'en-US';\r\n\r\n  // Initialize Web Speech API for text-to-speech\r\n  const synth = window.speechSynthesis;\r\n\r\n  // Function to start voice recognition\r\n  const startListening = useCallback(() => {\r\n    setIsListening(true);\r\n    recognition.start();\r\n  }, [recognition]);\r\n\r\n  // Function to send user transcript to the backend for an AI response\r\n  const sendToAI = useCallback(async (text) => {\r\n    const updatedHistory = [...interviewHistory, { role: 'user', text }];\r\n    setInterviewHistory(updatedHistory);\r\n    \r\n    try {\r\n      const response = await fetch('http://localhost:3001/api/chat', {\r\n        method: 'POST',\r\n        headers: { 'Content-Type': 'application/json' },\r\n        body: JSON.stringify({ chatHistory: updatedHistory, userText: text }),\r\n      });\r\n      const data = await response.json();\r\n      setAiText(data.message);\r\n      setQuestionCount(prevCount => prevCount + 1);\r\n    } catch (error) {\r\n      console.error('Error fetching AI response:', error);\r\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\r\n    }\r\n  }, [interviewHistory]);\r\n\r\n  // Main effect to handle the interview flow\r\n  // This effect runs whenever aiText changes, triggering the next step.\r\n  useEffect(() => {\r\n    if (aiText) {\r\n      // Add the AI's response to the history only after it has been spoken\r\n      setInterviewHistory(prevHistory => [...prevHistory, { role: 'ai', text: aiText }]);\r\n      \r\n      const utterance = new SpeechSynthesisUtterance(aiText);\r\n      utterance.onend = () => {\r\n        // After the AI finishes speaking, check if the interview is over\r\n        if (questionCount < 5) {\r\n          startListening();\r\n        } else {\r\n          // Interview completed, navigate to the result page with the full history.\r\n          onComplete([...interviewHistory, { role: 'ai', text: aiText }]); \r\n        }\r\n      };\r\n      synth.speak(utterance);\r\n    }\r\n  }, [aiText, synth, startListening, onComplete, interviewHistory, questionCount]);\r\n\r\n  // Effect to handle speech-to-text results and errors\r\n  useEffect(() => {\r\n    recognition.onresult = (event) => {\r\n      const last = event.results.length - 1;\r\n      const text = event.results[last][0].transcript;\r\n      setTranscript(text);\r\n      setIsListening(false);\r\n      sendToAI(text);\r\n    };\r\n\r\n    recognition.onerror = (event) => {\r\n      console.error('Speech recognition error:', event.error);\r\n      setIsListening(false);\r\n      // Automatically start listening again after an error to prevent a total freeze\r\n      if (questionCount < 5) {\r\n        startListening();\r\n      }\r\n    };\r\n\r\n    return () => {\r\n      recognition.stop();\r\n    };\r\n  }, [sendToAI, recognition, questionCount, startListening]);\r\n\r\n  return (\r\n    <div>\r\n      <p>AI: {aiText}</p>\r\n      <p>You: {transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")}</p>\r\n      \r\n      <div>\r\n        <button onClick={startListening} disabled={isListening}>\r\n          {isListening ? \"Listening...\" : \"Speak now\"}\r\n        </button>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default InterviewPage;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,WAAW,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEhE,MAAMC,aAAa,GAAGA,CAAC;EAAEC;AAAW,CAAC,KAAK;EAAAC,EAAA;EACxC,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,MAAM,EAAEC,SAAS,CAAC,GAAGb,QAAQ,CAAC,kFAAkF,CAAC;EACxH,MAAM,CAACc,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGf,QAAQ,CAAC,EAAE,CAAC;EAC5D,MAAM,CAACgB,aAAa,EAAEC,gBAAgB,CAAC,GAAGjB,QAAQ,CAAC,CAAC,CAAC;;EAErD;EACA;EACA,MAAMkB,WAAW,GAAG,KAAKC,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE,CAAC;EACtFH,WAAW,CAACI,UAAU,GAAG,KAAK;EAC9BJ,WAAW,CAACK,cAAc,GAAG,KAAK;EAClCL,WAAW,CAACM,IAAI,GAAG,OAAO;;EAE1B;EACA,MAAMC,KAAK,GAAGN,MAAM,CAACO,eAAe;;EAEpC;EACA,MAAMC,cAAc,GAAGzB,WAAW,CAAC,MAAM;IACvCS,cAAc,CAAC,IAAI,CAAC;IACpBO,WAAW,CAACU,KAAK,CAAC,CAAC;EACrB,CAAC,EAAE,CAACV,WAAW,CAAC,CAAC;;EAEjB;EACA,MAAMW,QAAQ,GAAG3B,WAAW,CAAC,MAAO4B,IAAI,IAAK;IAC3C,MAAMC,cAAc,GAAG,CAAC,GAAGjB,gBAAgB,EAAE;MAAEkB,IAAI,EAAE,MAAM;MAAEF;IAAK,CAAC,CAAC;IACpEf,mBAAmB,CAACgB,cAAc,CAAC;IAEnC,IAAI;MACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,gCAAgC,EAAE;QAC7DC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEC,WAAW,EAAET,cAAc;UAAEU,QAAQ,EAAEX;QAAK,CAAC;MACtE,CAAC,CAAC;MACF,MAAMY,IAAI,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;MAClC9B,SAAS,CAAC6B,IAAI,CAACE,OAAO,CAAC;MACvB3B,gBAAgB,CAAC4B,SAAS,IAAIA,SAAS,GAAG,CAAC,CAAC;IAC9C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACnDjC,SAAS,CAAC,6DAA6D,CAAC;IAC1E;EACF,CAAC,EAAE,CAACC,gBAAgB,CAAC,CAAC;;EAEtB;EACA;EACAb,SAAS,CAAC,MAAM;IACd,IAAIW,MAAM,EAAE;MACV;MACAG,mBAAmB,CAACiC,WAAW,IAAI,CAAC,GAAGA,WAAW,EAAE;QAAEhB,IAAI,EAAE,IAAI;QAAEF,IAAI,EAAElB;MAAO,CAAC,CAAC,CAAC;MAElF,MAAMqC,SAAS,GAAG,IAAIC,wBAAwB,CAACtC,MAAM,CAAC;MACtDqC,SAAS,CAACE,KAAK,GAAG,MAAM;QACtB;QACA,IAAInC,aAAa,GAAG,CAAC,EAAE;UACrBW,cAAc,CAAC,CAAC;QAClB,CAAC,MAAM;UACL;UACArB,UAAU,CAAC,CAAC,GAAGQ,gBAAgB,EAAE;YAAEkB,IAAI,EAAE,IAAI;YAAEF,IAAI,EAAElB;UAAO,CAAC,CAAC,CAAC;QACjE;MACF,CAAC;MACDa,KAAK,CAAC2B,KAAK,CAACH,SAAS,CAAC;IACxB;EACF,CAAC,EAAE,CAACrC,MAAM,EAAEa,KAAK,EAAEE,cAAc,EAAErB,UAAU,EAAEQ,gBAAgB,EAAEE,aAAa,CAAC,CAAC;;EAEhF;EACAf,SAAS,CAAC,MAAM;IACdiB,WAAW,CAACmC,QAAQ,GAAIC,KAAK,IAAK;MAChC,MAAMC,IAAI,GAAGD,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACrC,MAAM3B,IAAI,GAAGwB,KAAK,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC/C,UAAU;MAC9CC,aAAa,CAACqB,IAAI,CAAC;MACnBnB,cAAc,CAAC,KAAK,CAAC;MACrBkB,QAAQ,CAACC,IAAI,CAAC;IAChB,CAAC;IAEDZ,WAAW,CAACwC,OAAO,GAAIJ,KAAK,IAAK;MAC/BP,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEQ,KAAK,CAACR,KAAK,CAAC;MACvDnC,cAAc,CAAC,KAAK,CAAC;MACrB;MACA,IAAIK,aAAa,GAAG,CAAC,EAAE;QACrBW,cAAc,CAAC,CAAC;MAClB;IACF,CAAC;IAED,OAAO,MAAM;MACXT,WAAW,CAACyC,IAAI,CAAC,CAAC;IACpB,CAAC;EACH,CAAC,EAAE,CAAC9B,QAAQ,EAAEX,WAAW,EAAEF,aAAa,EAAEW,cAAc,CAAC,CAAC;EAE1D,oBACEvB,OAAA;IAAAwD,QAAA,gBACExD,OAAA;MAAAwD,QAAA,GAAG,MAAI,EAAChD,MAAM;IAAA;MAAAiD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACnB5D,OAAA;MAAAwD,QAAA,GAAG,OAAK,EAACpD,UAAU,KAAKE,WAAW,GAAG,cAAc,GAAG,8BAA8B,CAAC;IAAA;MAAAmD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAE3F5D,OAAA;MAAAwD,QAAA,eACExD,OAAA;QAAQ6D,OAAO,EAAEtC,cAAe;QAACuC,QAAQ,EAAExD,WAAY;QAAAkD,QAAA,EACpDlD,WAAW,GAAG,cAAc,GAAG;MAAW;QAAAmD,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACrC;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAACzD,EAAA,CApGIF,aAAa;AAAA8D,EAAA,GAAb9D,aAAa;AAsGnB,eAAeA,aAAa;AAAC,IAAA8D,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}