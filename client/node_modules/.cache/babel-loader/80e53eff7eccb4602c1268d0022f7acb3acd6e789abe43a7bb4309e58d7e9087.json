{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\ai-interview-model\\\\client\\\\src\\\\InterviewPage.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useCallback } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst InterviewPage = ({\n  onComplete\n}) => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [aiText, setAiText] = useState(\"\");\n  const [interviewHistory, setInterviewHistory] = useState([]);\n  const [questionCount, setQuestionCount] = useState(0);\n\n  // Initialize Web Speech API for speech-to-text\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n  recognition.continuous = false;\n  recognition.interimResults = false;\n  recognition.lang = 'en-US';\n\n  // Initialize Web Speech API for text-to-speech\n  const synth = window.speechSynthesis;\n\n  // Function to send user transcript to the backend for an AI response\n  const sendToAI = useCallback(async text => {\n    // Add user's response to history\n    const updatedHistory = [...interviewHistory, {\n      role: 'user',\n      text\n    }];\n    setInterviewHistory(updatedHistory);\n    try {\n      const response = await fetch('http://localhost:3001/api/chat', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          chatHistory: updatedHistory,\n          userText: text\n        })\n      });\n      const data = await response.json();\n      setAiText(data.message);\n      setQuestionCount(prevCount => prevCount + 1);\n    } catch (error) {\n      console.error('Error fetching AI response:', error);\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\n    }\n  }, [interviewHistory]);\n\n  // Function to start voice recognition\n  const startListening = () => {\n    setIsListening(true);\n    recognition.start();\n  };\n\n  // Main effect to handle the interview flow\n  useEffect(() => {\n    // Initial greeting on component mount\n    if (aiText === \"\") {\n      setAiText(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\n      return;\n    }\n\n    // Play AI text and then start listening\n    if (aiText) {\n      const utterance = new SpeechSynthesisUtterance(aiText);\n      utterance.onend = () => {\n        // After the AI finishes speaking, check if the interview is over\n        if (questionCount < 5) {\n          startListening();\n        } else {\n          // Interview completed, send the full history to the result page.\n          onComplete([...interviewHistory, {\n            role: 'ai',\n            text: aiText\n          }]);\n        }\n      };\n      synth.speak(utterance);\n      setInterviewHistory(prevHistory => [...prevHistory, {\n        role: 'ai',\n        text: aiText\n      }]);\n    }\n  }, [aiText, synth, recognition, interviewHistory, questionCount, onComplete, startListening]);\n\n  // Effect to handle speech-to-text results and errors\n  useEffect(() => {\n    recognition.onresult = event => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      setTranscript(text);\n      setIsListening(false);\n      sendToAI(text);\n    };\n    recognition.onerror = event => {\n      console.error('Speech recognition error:', event.error);\n      setIsListening(false);\n    };\n    return () => {\n      recognition.stop();\n    };\n  }, [sendToAI, recognition]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"AI: \", aiText]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"You: \", transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: startListening,\n        disabled: isListening,\n        children: isListening ? \"Listening...\" : \"Speak now\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 97,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 96,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 92,\n    columnNumber: 5\n  }, this);\n};\n_s(InterviewPage, \"7Kyodscf7+vzc/dHOdNjb24EOmE=\");\n_c = InterviewPage;\nexport default InterviewPage;\nvar _c;\n$RefreshReg$(_c, \"InterviewPage\");","map":{"version":3,"names":["React","useState","useEffect","useCallback","jsxDEV","_jsxDEV","InterviewPage","onComplete","_s","transcript","setTranscript","isListening","setIsListening","aiText","setAiText","interviewHistory","setInterviewHistory","questionCount","setQuestionCount","recognition","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","synth","speechSynthesis","sendToAI","text","updatedHistory","role","response","fetch","method","headers","body","JSON","stringify","chatHistory","userText","data","json","message","prevCount","error","console","startListening","start","utterance","SpeechSynthesisUtterance","onend","speak","prevHistory","onresult","event","last","results","length","onerror","stop","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","_c","$RefreshReg$"],"sources":["C:/Users/Lenovo/Desktop/ai-interview-model/client/src/InterviewPage.js"],"sourcesContent":["import React, { useState, useEffect, useCallback } from 'react';\r\n\r\nconst InterviewPage = ({ onComplete }) => {\r\n  const [transcript, setTranscript] = useState('');\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [aiText, setAiText] = useState(\"\");\r\n  const [interviewHistory, setInterviewHistory] = useState([]);\r\n  const [questionCount, setQuestionCount] = useState(0);\r\n\r\n  // Initialize Web Speech API for speech-to-text\r\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\r\n  recognition.continuous = false;\r\n  recognition.interimResults = false;\r\n  recognition.lang = 'en-US';\r\n\r\n  // Initialize Web Speech API for text-to-speech\r\n  const synth = window.speechSynthesis;\r\n\r\n  // Function to send user transcript to the backend for an AI response\r\n  const sendToAI = useCallback(async (text) => {\r\n    // Add user's response to history\r\n    const updatedHistory = [...interviewHistory, { role: 'user', text }];\r\n    setInterviewHistory(updatedHistory);\r\n    \r\n    try {\r\n      const response = await fetch('http://localhost:3001/api/chat', {\r\n        method: 'POST',\r\n        headers: { 'Content-Type': 'application/json' },\r\n        body: JSON.stringify({ chatHistory: updatedHistory, userText: text }),\r\n      });\r\n      const data = await response.json();\r\n      setAiText(data.message);\r\n      setQuestionCount(prevCount => prevCount + 1);\r\n    } catch (error) {\r\n      console.error('Error fetching AI response:', error);\r\n      setAiText(\"I am sorry, there was an error. Could you please try again?\");\r\n    }\r\n  }, [interviewHistory]);\r\n\r\n  // Function to start voice recognition\r\n  const startListening = () => {\r\n    setIsListening(true);\r\n    recognition.start();\r\n  };\r\n\r\n  // Main effect to handle the interview flow\r\n  useEffect(() => {\r\n    // Initial greeting on component mount\r\n    if (aiText === \"\") {\r\n      setAiText(\"Hello! Let's begin the interview. Could you please tell me a bit about yourself?\");\r\n      return;\r\n    }\r\n\r\n    // Play AI text and then start listening\r\n    if (aiText) {\r\n      const utterance = new SpeechSynthesisUtterance(aiText);\r\n      utterance.onend = () => {\r\n        // After the AI finishes speaking, check if the interview is over\r\n        if (questionCount < 5) {\r\n          startListening();\r\n        } else {\r\n          // Interview completed, send the full history to the result page.\r\n          onComplete([...interviewHistory, { role: 'ai', text: aiText }]); \r\n        }\r\n      };\r\n      synth.speak(utterance);\r\n      setInterviewHistory(prevHistory => [...prevHistory, { role: 'ai', text: aiText }]);\r\n    }\r\n  }, [aiText, synth, recognition, interviewHistory, questionCount, onComplete, startListening]);\r\n\r\n  // Effect to handle speech-to-text results and errors\r\n  useEffect(() => {\r\n    recognition.onresult = (event) => {\r\n      const last = event.results.length - 1;\r\n      const text = event.results[last][0].transcript;\r\n      setTranscript(text);\r\n      setIsListening(false);\r\n      sendToAI(text);\r\n    };\r\n\r\n    recognition.onerror = (event) => {\r\n      console.error('Speech recognition error:', event.error);\r\n      setIsListening(false);\r\n    };\r\n\r\n    return () => {\r\n      recognition.stop();\r\n    };\r\n  }, [sendToAI, recognition]);\r\n\r\n  return (\r\n    <div>\r\n      <p>AI: {aiText}</p>\r\n      <p>You: {transcript || (isListening ? \"Listening...\" : \"Waiting for your response...\")}</p>\r\n      \r\n      <div>\r\n        <button onClick={startListening} disabled={isListening}>\r\n          {isListening ? \"Listening...\" : \"Speak now\"}\r\n        </button>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default InterviewPage;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,WAAW,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEhE,MAAMC,aAAa,GAAGA,CAAC;EAAEC;AAAW,CAAC,KAAK;EAAAC,EAAA;EACxC,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,MAAM,EAAEC,SAAS,CAAC,GAAGb,QAAQ,CAAC,EAAE,CAAC;EACxC,MAAM,CAACc,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGf,QAAQ,CAAC,EAAE,CAAC;EAC5D,MAAM,CAACgB,aAAa,EAAEC,gBAAgB,CAAC,GAAGjB,QAAQ,CAAC,CAAC,CAAC;;EAErD;EACA,MAAMkB,WAAW,GAAG,KAAKC,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE,CAAC;EACtFH,WAAW,CAACI,UAAU,GAAG,KAAK;EAC9BJ,WAAW,CAACK,cAAc,GAAG,KAAK;EAClCL,WAAW,CAACM,IAAI,GAAG,OAAO;;EAE1B;EACA,MAAMC,KAAK,GAAGN,MAAM,CAACO,eAAe;;EAEpC;EACA,MAAMC,QAAQ,GAAGzB,WAAW,CAAC,MAAO0B,IAAI,IAAK;IAC3C;IACA,MAAMC,cAAc,GAAG,CAAC,GAAGf,gBAAgB,EAAE;MAAEgB,IAAI,EAAE,MAAM;MAAEF;IAAK,CAAC,CAAC;IACpEb,mBAAmB,CAACc,cAAc,CAAC;IAEnC,IAAI;MACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,gCAAgC,EAAE;QAC7DC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEC,WAAW,EAAET,cAAc;UAAEU,QAAQ,EAAEX;QAAK,CAAC;MACtE,CAAC,CAAC;MACF,MAAMY,IAAI,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;MAClC5B,SAAS,CAAC2B,IAAI,CAACE,OAAO,CAAC;MACvBzB,gBAAgB,CAAC0B,SAAS,IAAIA,SAAS,GAAG,CAAC,CAAC;IAC9C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACnD/B,SAAS,CAAC,6DAA6D,CAAC;IAC1E;EACF,CAAC,EAAE,CAACC,gBAAgB,CAAC,CAAC;;EAEtB;EACA,MAAMgC,cAAc,GAAGA,CAAA,KAAM;IAC3BnC,cAAc,CAAC,IAAI,CAAC;IACpBO,WAAW,CAAC6B,KAAK,CAAC,CAAC;EACrB,CAAC;;EAED;EACA9C,SAAS,CAAC,MAAM;IACd;IACA,IAAIW,MAAM,KAAK,EAAE,EAAE;MACjBC,SAAS,CAAC,kFAAkF,CAAC;MAC7F;IACF;;IAEA;IACA,IAAID,MAAM,EAAE;MACV,MAAMoC,SAAS,GAAG,IAAIC,wBAAwB,CAACrC,MAAM,CAAC;MACtDoC,SAAS,CAACE,KAAK,GAAG,MAAM;QACtB;QACA,IAAIlC,aAAa,GAAG,CAAC,EAAE;UACrB8B,cAAc,CAAC,CAAC;QAClB,CAAC,MAAM;UACL;UACAxC,UAAU,CAAC,CAAC,GAAGQ,gBAAgB,EAAE;YAAEgB,IAAI,EAAE,IAAI;YAAEF,IAAI,EAAEhB;UAAO,CAAC,CAAC,CAAC;QACjE;MACF,CAAC;MACDa,KAAK,CAAC0B,KAAK,CAACH,SAAS,CAAC;MACtBjC,mBAAmB,CAACqC,WAAW,IAAI,CAAC,GAAGA,WAAW,EAAE;QAAEtB,IAAI,EAAE,IAAI;QAAEF,IAAI,EAAEhB;MAAO,CAAC,CAAC,CAAC;IACpF;EACF,CAAC,EAAE,CAACA,MAAM,EAAEa,KAAK,EAAEP,WAAW,EAAEJ,gBAAgB,EAAEE,aAAa,EAAEV,UAAU,EAAEwC,cAAc,CAAC,CAAC;;EAE7F;EACA7C,SAAS,CAAC,MAAM;IACdiB,WAAW,CAACmC,QAAQ,GAAIC,KAAK,IAAK;MAChC,MAAMC,IAAI,GAAGD,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC;MACrC,MAAM7B,IAAI,GAAG0B,KAAK,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC/C,UAAU;MAC9CC,aAAa,CAACmB,IAAI,CAAC;MACnBjB,cAAc,CAAC,KAAK,CAAC;MACrBgB,QAAQ,CAACC,IAAI,CAAC;IAChB,CAAC;IAEDV,WAAW,CAACwC,OAAO,GAAIJ,KAAK,IAAK;MAC/BT,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEU,KAAK,CAACV,KAAK,CAAC;MACvDjC,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC;IAED,OAAO,MAAM;MACXO,WAAW,CAACyC,IAAI,CAAC,CAAC;IACpB,CAAC;EACH,CAAC,EAAE,CAAChC,QAAQ,EAAET,WAAW,CAAC,CAAC;EAE3B,oBACEd,OAAA;IAAAwD,QAAA,gBACExD,OAAA;MAAAwD,QAAA,GAAG,MAAI,EAAChD,MAAM;IAAA;MAAAiD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACnB5D,OAAA;MAAAwD,QAAA,GAAG,OAAK,EAACpD,UAAU,KAAKE,WAAW,GAAG,cAAc,GAAG,8BAA8B,CAAC;IAAA;MAAAmD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAE3F5D,OAAA;MAAAwD,QAAA,eACExD,OAAA;QAAQ6D,OAAO,EAAEnB,cAAe;QAACoB,QAAQ,EAAExD,WAAY;QAAAkD,QAAA,EACpDlD,WAAW,GAAG,cAAc,GAAG;MAAW;QAAAmD,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACrC;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAACzD,EAAA,CApGIF,aAAa;AAAA8D,EAAA,GAAb9D,aAAa;AAsGnB,eAAeA,aAAa;AAAC,IAAA8D,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}